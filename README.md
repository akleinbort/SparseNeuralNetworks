# SparseNeuralNetworks
According to Haim Sompolinsky:
<p>"Neuronal activity arises from an interaction between ongoing firing generated spontaneously by neural circuits and responses driven by external stimuli... We find that inputs not only drive network responses, but they also actively suppress ongoing activity, ultimately leading to a phase transition in which chaos is completely eliminated."</p>


Moreover, sparse synaptic wiring can optimize a neural representation and maximizing dimension predicts the degree of connectivity for cerebellum-like circuits, where bi-directionality is over-represented. [^1] 

Thus, we start by verifying the supression of chaos in the presence of bi-directionality and sparsity. We then characterize how the network and each individual node performs FORCE learning.

[^1]: https://www.ncbi.nlm.nih.gov/pubmed/28215558
